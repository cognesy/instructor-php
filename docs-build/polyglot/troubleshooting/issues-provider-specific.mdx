---
title: 'Provider-Specific Issues'
description: 'Learn how to troubleshoot provider-specific issues when using Polyglot.'
---

Each LLM provider has unique quirks and issues. This section covers common provider-specific issues and how to resolve them.


## OpenAI

1. **Organization IDs**: Set the organization ID if using a shared account
```php
// In config/llm.php
'metadata' => [
    'organization' => 'org-your-organization-id',
],
// @doctest id="cd7e"
```

2. **API Versions**: Pay attention to API version changes
```php
// Updates to OpenAI API may require changes to your code
// Monitor OpenAI's release notes for changes
// @doctest id="51fd"
```

## Anthropic

1. **Message Format**: Anthropic uses a different message format
```php
// Polyglot handles this automatically, but be aware when debugging
// @doctest id="4e0a"
```

2. **Tool Support**: Tool support has specific requirements
```php
// When using tools with Anthropic, check their latest documentation
// for supported features and limitations
// @doctest id="fe3b"
```

## Mistral

1. **Rate Limits**: Mistral has strict rate limits on free tier
```php
// Implement more aggressive rate limiting for Mistral
// @doctest id="5775"
```


## Ollama

1. **Local Setup**: Ensure Ollama is properly installed and running
```bash
# Check if Ollama is running
curl http://localhost:11434/api/version
# @doctest id="67e9"
```

2. **Model Availability**: Download models before using them
```bash
# Pull a model before using it
ollama pull llama2
# @doctest id="77f5"
```
