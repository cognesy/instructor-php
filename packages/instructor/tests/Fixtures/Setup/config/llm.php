<?php

use Cognesy\Config\Env;

return [
    'defaultPreset' => 'openai',

    'presets' => [
        'a21' => [
            'providerType' => 'a21',
            'apiUrl' => 'https://api.ai21.com/studio/v1',
            'apiKey' => Env::get('A21_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'jamba-mini',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 256_000,
            'maxOutputLength' => 4096,
        ],
        'anthropic' => [
            'providerType' => 'anthropic',
            'apiUrl' => 'https://api.anthropic.com/v1',
            'apiKey' => Env::get('ANTHROPIC_API_KEY', ''),
            'endpoint' => '/messages',
            'metadata' => [
                'apiVersion' => '2023-06-01',
                'beta' => 'prompt-caching-2024-07-31',
            ],
            'defaultModel' => 'claude-3-haiku-20240307',
            'defaultOutputMode' => 'tools',
            'defaultMaxTokens' => 1024,
            'contextLength' => 200_000,
            'maxOutputLength' => 8192,
        ],
        'azure' => [
            'providerType' => 'azure',
            'apiUrl' => 'https://{resourceName}.openai.azure.com/openai/deployments/{deploymentId}',
            'apiKey' => Env::get('AZURE_OPENAI_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'metadata' => [
                'apiVersion' => '2024-08-01-preview',
                'resourceName' => 'instructor-dev',
                'deploymentId' => 'gpt-4o-mini',
            ],
            'defaultModel' => 'gpt-4o-mini',
            'defaultOutputMode' => 'json_schema',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 16384,
        ],
        'cerebras' => [
            'providerType' => 'cerebras',
            'apiUrl' => 'https://api.cerebras.ai/v1',
            'apiKey' => Env::get('CEREBRAS_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'llama3.1-8b',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 2048,
        ],
        'cohere' => [
            'providerType' => 'cohere',
            'apiUrl' => 'https://api.cohere.ai/v2',
            'apiKey' => Env::get('COHERE_API_KEY', ''),
            'endpoint' => '/chat',
            'defaultModel' => 'command-r-plus-08-2024',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 4096,
        ],
        'deepseek' => [
            'providerType' => 'deepseek',
            'apiUrl' => 'https://api.deepseek.com',
            'apiKey' => Env::get('DEEPSEEK_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'deepseek-chat',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 8192,
        ],
        'deepseek-r' => [
            'providerType' => 'deepseek',
            'apiUrl' => 'https://api.deepseek.com',
            'apiKey' => Env::get('DEEPSEEK_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'deepseek-reasoner',
            'defaultOutputMode' => 'md_json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 8192,
        ],
        'fireworks' => [
            'providerType' => 'fireworks',
            'apiUrl' => 'https://api.fireworks.ai/inference/v1',
            'apiKey' => Env::get('FIREWORKS_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'accounts/fireworks/models/llama4-maverick-instruct-basic',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 65_000,
            'maxOutputLength' => 4096,
        ],
        'gemini' => [
            'providerType' => 'gemini',
            'apiUrl' => 'https://generativelanguage.googleapis.com/v1beta',
            'apiKey' => Env::get('GEMINI_API_KEY', ''),
            'endpoint' => '/models/{model}:generateContent',
            'defaultModel' => 'gemini-1.5-flash',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 1_000_000,
            'maxOutputLength' => 8192,
        ],
        'gemini-oai' => [
            'providerType' => 'gemini-oai',
            'apiUrl' => 'https://generativelanguage.googleapis.com/v1beta/openai',
            'apiKey' => Env::get('GEMINI_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'gemini-1.5-flash',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 1_000_000,
            'maxOutputLength' => 8192,
        ],
        'groq' => [
            'providerType' => 'groq',
            'apiUrl' => 'https://api.groq.com/openai/v1',
            'apiKey' => Env::get('GROQ_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'meta-llama/llama-4-scout-17b-16e-instruct', //'llama-3.3-70b-versatile', // 'gemma2-9b-it',
            'defaultOutputMode' => 'json_schema',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 2048,
        ],
        'huggingface' => [
            'providerType' => 'huggingface',
            'apiUrl' => 'https://router.huggingface.co/{providerId}/v1',
            'apiKey' => Env::get('HUGGINGFACE_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'metadata' => [
                'providerId' => 'hf-inference/models/microsoft/phi-4',
            ],
            'defaultModel' => 'microsoft/phi-4',
            'defaultOutputMode' => 'text',
            'defaultMaxTokens' => 1024,
            'contextLength' => 32_000,
            'maxOutputLength' => 4096,
        ],
        'meta' => [
            'providerType' => 'meta',
            'apiUrl' => 'https://openrouter.ai/api/v1',
            'apiKey' => Env::get('OPENROUTER_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'meta-llama/llama-3.3-8b-instruct:free',
            'defaultOutputMode' => 'json_schema',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 8192,
        ],
        'minimaxi' => [
            'providerType' => 'minimaxi',
            'apiUrl' => 'https://api.minimaxi.chat/v1',
            'apiKey' => Env::get('MINIMAXI_API_KEY', ''),
            'endpoint' => '/text/chatcompletion_v2',
            'defaultModel' => 'MiniMax-Text-01', // 'MiniMax-Text-01',
            'defaultOutputMode' => 'md_json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 1_000_000,
            'maxOutputLength' => 4096,
        ],
        'minimaxi-oai' => [
            'providerType' => 'minimaxi',
            'apiUrl' => 'https://api.minimaxi.chat/v1',
            'apiKey' => Env::get('MINIMAXI_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'MiniMax-Text-01', // 'MiniMax-Text-01',
            'defaultOutputMode' => 'md_json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 1_000_000,
            'maxOutputLength' => 4096,
        ],
        'mistral' => [
            'providerType' => 'mistral',
            'apiUrl' => 'https://api.mistral.ai/v1',
            'apiKey' => Env::get('MISTRAL_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'mistral-small-latest',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 4096,
        ],
        'moonshot-kimi' => [
            'providerType' => 'moonshot',
            'apiUrl' => 'https://api.moonshot.cn/v1',
            'apiKey' => Env::get('MOONSHOT_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'kimi-latest',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 4096,
        ],
        'ollama' => [
            'providerType' => 'ollama',
            'apiUrl' => 'http://localhost:11434/v1',
            'apiKey' => Env::get('OLLAMA_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'gemma3:1b', // 'qwen2.5-coder:3b', //'gemma2:2b',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'httpClientPreset' => 'http-ollama',
            'contextLength' => 128_000,
            'maxOutputLength' => 8192,
        ],
        'openai' => [
            'providerType' => 'openai',
            'apiUrl' => 'https://api.openai.com/v1',
            'apiKey' => Env::get('OPENAI_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'metadata' => [
                'organization' => '',
                'project' => '',
            ],
            'defaultModel' => 'gpt-4o-mini',
            'defaultOutputMode' => 'json_schema',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 16384,
        ],
        'openrouter' => [
            'providerType' => 'openrouter',
            'apiUrl' => 'https://openrouter.ai/api/v1',
            'apiKey' => Env::get('OPENROUTER_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'google/gemini-2.0-flash-001', // 'qwen/qwen3-0.6b-04-28:free',
            'defaultOutputMode' => 'json_schema',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 8192,
        ],
        'perplexity' => [
            'providerType' => 'perplexity',
            'apiUrl' => 'https://api.perplexity.ai',
            'apiKey' => Env::get('PERPLEXITY_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'sonar',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 2048,
        ],
        'sambanova' => [
            'providerType' => 'sambanova',
            'apiUrl' => 'https://api.sambanova.ai/v1',
            'apiKey' => Env::get('SAMBANOVA_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'Meta-Llama-3.1-8B-Instruct',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 2048,
        ],
        'together' => [
            'providerType' => 'together',
            'apiUrl' => 'https://api.together.xyz/v1',
            'apiKey' => Env::get('TOGETHER_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 4096,
        ],
        'xai' => [
            'providerType' => 'xai',
            'apiUrl' => 'https://api.x.ai/v1',
            'apiKey' => Env::get('XAI_API_KEY', ''),
            'endpoint' => '/chat/completions',
            'defaultModel' => 'grok-3',
            'defaultOutputMode' => 'json',
            'defaultMaxTokens' => 1024,
            'contextLength' => 128_000,
            'maxOutputLength' => 128_000,
        ],
    ],
];
