---
title: Introduction
description: 'Structured data processing in PHP, powered by LLMs. Designed for simplicity, transparency, and control.'
---

<img
  className="block dark:hidden"
  src="/images/hero-light.svg"
  alt="Hero Light"
/>
<img
  className="hidden dark:block"
  src="/images/hero-dark.svg"
  alt="Hero Dark"
/>

## Feature highlights

Instructor is designed to make it easy to process data with LLMs in PHP. Here are some of the key features of the library:

### Core features

- Get structured responses from LLM inference
- Validation of returned data
- Automated retries in case of errors when LLM responds with invalid data

### Flexible inputs

- Process various types of input data: text, series of chat messages or images
- 'Structured-to-structured' processing - provide object or array as an input and get object with the results of inference back
- Demonstrate examples to improve the quality of inference

### Customizable outputs

- Define response data model the way to need: type-hinted classes, JSON Schema arrays, or dynamically define your data shapes with Structures
- Customize prompts and retry prompts
- Use attributes or PHP DocBlocks to provide additional instructions for LLM
- Customize response model processing by providing your own implementation of schema, deserialization, validation and transformation interfaces

### Sync and streaming support

- Receive synchronous or streaming responses
- Get partial updates & stream completed sequence items

### Observability

- Get detailed insight into internal processing via events

### Support for multiple LLMs / API providers

- Use multiple LLM API providers (incl. OpenAI,  Anthropic, Cohere, Azure, Groq, Mistral, Anyscale, Fireworks AI, Ollama, OpenRouter, Together AI)
- Use local models with Ollama

### Documentation and examples

- Learn more from growing documentation and 50+ cookbooks




## Instructor in Other Languages

Check out implementations in other languages below:

- [Python](https://www.github.com/jxnl/instructor) (original)
- [Javascript](https://github.com/instructor-ai/instructor-js) (port)
- [Elixir](https://github.com/thmsmlr/instructor_ex/) (port)
- [Ruby](https://ruby.useinstructor.com/) (port)
- [Go](https://go.useinstructor.com/) (port)

If you want to port Instructor to another language, please reach out to us on [Twitter](https://twitter.com/jxnlco) we'd love to help you get started!




## How Instructor Enhances Your Workflow

Instructor introduces three key enhancements compared to direct API usage.

### Response Model

You just specify a PHP class to extract data into via the 'magic' of LLM chat completion. And that's it.

Instructor reduces brittleness of the code extracting the information from textual data by leveraging structured LLM responses.

Instructor helps you write simpler, easier to understand code - you no longer have to define lengthy function call definitions or write code for assigning returned JSON into target data objects.

### Validation

Response model generated by LLM can be automatically validated, following set of rules. Currently, Instructor supports only Symfony validation.

You can also provide a context object to use enhanced validator capabilities.

### Max Retries

You can set the number of retry attempts for requests.

Instructor will repeat requests in case of validation or deserialization error up to the specified number of times, trying to get a valid response from LLM.




## Setting up

The first step to data processing with LLMs is setting up your editing environments.

<CardGroup cols={1}>
    <Card
        title="Install Instructor"
        icon="pen-to-square"
        href="/setup"
    >
        Setup your API keys in .env file to access LLM API provider
    </Card>
    <Card
        title="Run examples"
        icon="image"
        href="/examples/index"
    >
        Run examples to see how Instructor in action
    </Card>
</CardGroup>




## Using Instructor

Learn how to use Instructor to process your data with LLMs.

<CardGroup cols={2}>
  <Card
    title="Concepts"
    icon="palette"
    href="https://mintlify.com/docs/settings/global"
  >
    Understand basic concepts behind Instructor
  </Card>
  <Card
    title="Usage"
    icon="code"
    href="https://mintlify.com/docs/api-playground/openapi"
  >
    Learn how to use Instructor in your projects
  </Card>
  <Card
    title="Data model"
    icon="screwdriver-wrench"
    href="https://mintlify.com/docs/components/accordion"
  >
    Find out the ways to define response data models
  </Card>
  <Card
    title="Validation"
    icon="stars"
    href="https://mintlify.com/customers"
  >
    Use validation to automatically retry for incorrect LLM responses
  </Card>
</CardGroup>
