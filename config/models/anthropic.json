{
  "data":
  [
    {
      "id": "anthropic/claude-3-opus",
      "code": "claude-3-opus-20240229",
      "name": "Anthropic: Claude 3 Opus (self-moderated)",
      "description": "This is a lower-latency version of [Claude 3 Opus](/models/anthropic/claude-3-opus), made available in collaboration with Anthropic, that is self-moderated: response moderation happens on the model's side instead of OpenRouter's. It's in beta, and may change in the future.\n\nClaude 3 Opus is Anthropic's most powerful model for highly complex tasks. It boasts top-level performance, intelligence, fluency, and understanding.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
      "pricing":
      {
        "prompt": "0.000015",
        "completion": "0.000075",
        "image": "0.024",
        "request": "0"
      },
      "context_length": 200000,
      "architecture":
      {
        "modality": "multimodal",
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "top_provider":
      {
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": null
    },
    {
      "id": "anthropic/claude-3-sonnet",
      "code": "claude-3-sonnet-20240229",
      "name": "Anthropic: Claude 3 Sonnet (self-moderated)",
      "description": "This is a lower-latency version of [Claude 3 Sonnet](/models/anthropic/claude-3-sonnet), made available in collaboration with Anthropic, that is self-moderated: response moderation happens on the model's side instead of OpenRouter's. It's in beta, and may change in the future.\n\nClaude 3 Sonnet is an ideal balance of intelligence and speed for enterprise workloads. Maximum utility at a lower price, dependable, balanced for scaled deployments.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
      "pricing":
      {
        "prompt": "0.000003",
        "completion": "0.000015",
        "image": "0.0048",
        "request": "0"
      },
      "context_length": 200000,
      "architecture":
      {
        "modality": "multimodal",
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "top_provider":
      {
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": null
    },
    {
      "id": "anthropic/claude-3.5-sonnet",
      "name": "Anthropic: Claude 3.5 Sonnet (self-moderated)",
      "code": "claude-3-5-sonnet-20240620",
      "description": "This is a lower-latency version of [Claude 3.5 Sonnet](/models/anthropic/claude-3.5-sonnet), made available in collaboration with Anthropic, that is self-moderated: response moderation happens on the model's side instead of OpenRouter's. It's in beta, and may change in the future.\n\nClaude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Autonomously writes, edits, and runs code with reasoning and troubleshooting\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\n#multimodal",
      "pricing":
      {
        "prompt": "0.000003",
        "completion": "0.000015",
        "image": "0.0048",
        "request": "0"
      },
      "context_length": 200000,
      "architecture":
      {
        "modality": "multimodal",
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "top_provider":
      {
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": null
    },
    {
      "id": "anthropic/claude-3-haiku",
      "name": "Anthropic: Claude 3 Haiku (self-moderated)",
      "code": "claude-3-haiku-20240307",
      "description": "This is a lower-latency version of [Claude 3 Haiku](/models/anthropic/claude-3-haiku), made available in collaboration with Anthropic, that is self-moderated: response moderation happens on the model's side instead of OpenRouter's. It's in beta, and may change in the future.\n\nClaude 3 Haiku is Anthropic's fastest and most compact model for\nnear-instant responsiveness. Quick and accurate targeted performance.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-haiku)\n\n#multimodal",
      "pricing":
      {
        "prompt": "0.00000025",
        "completion": "0.00000125",
        "image": "0.0004",
        "request": "0"
      },
      "context_length": 200000,
      "architecture":
      {
        "modality": "multimodal",
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "top_provider":
      {
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": null
    },
    {
      "id": "anthropic/claude-2:beta",
      "name": "Anthropic: Claude v2 (self-moderated)",
      "description": "This is a lower-latency version of [Claude v2](/models/anthropic/claude-2), made available in collaboration with Anthropic, that is self-moderated: response moderation happens on the model's side instead of OpenRouter's. It's in beta, and may change in the future.\n\nClaude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
      "pricing":
      {
        "prompt": "0.000008",
        "completion": "0.000024",
        "image": "0",
        "request": "0"
      },
      "context_length": 200000,
      "architecture":
      {
        "modality": "text",
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "top_provider":
      {
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": null
    },
    {
      "id": "anthropic/claude-2.0:beta",
      "name": "Anthropic: Claude v2.0 (self-moderated)",
      "description": "This is a lower-latency version of [Claude v2.0](/models/anthropic/claude-2.0), made available in collaboration with Anthropic, that is self-moderated: response moderation happens on the model's side instead of OpenRouter's. It's in beta, and may change in the future.\n\nAnthropic's flagship model. Superior performance on tasks that require complex reasoning. Supports hundreds of pages of text.",
      "pricing":
      {
        "prompt": "0.000008",
        "completion": "0.000024",
        "image": "0",
        "request": "0"
      },
      "context_length": 100000,
      "architecture":
      {
        "modality": "text",
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "top_provider":
      {
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": null
    },
    {
      "id": "anthropic/claude-2.1:beta",
      "name": "Anthropic: Claude v2.1 (self-moderated)",
      "description": "This is a lower-latency version of [Claude v2.1](/models/anthropic/claude-2.1), made available in collaboration with Anthropic, that is self-moderated: response moderation happens on the model's side instead of OpenRouter's. It's in beta, and may change in the future.\n\nClaude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
      "pricing":
      {
        "prompt": "0.000008",
        "completion": "0.000024",
        "image": "0",
        "request": "0"
      },
      "context_length": 200000,
      "architecture":
      {
        "modality": "text",
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "top_provider":
      {
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": null
    },
    {
      "id": "anthropic/claude-instant-1:beta",
      "name": "Anthropic: Claude Instant v1 (self-moderated)",
      "description": "This is a lower-latency version of [Claude Instant v1](/models/anthropic/claude-instant-1), made available in collaboration with Anthropic, that is self-moderated: response moderation happens on the model's side instead of OpenRouter's. It's in beta, and may change in the future.\n\nAnthropic's model for low-latency, high throughput text generation. Supports hundreds of pages of text.",
      "pricing":
      {
        "prompt": "0.0000008",
        "completion": "0.0000024",
        "image": "0",
        "request": "0"
      },
      "context_length": 100000,
      "architecture":
      {
        "modality": "text",
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "top_provider":
      {
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": null
    }
  ]
}
